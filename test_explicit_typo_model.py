#!/usr/bin/env python3
"""
Test the explicit typo correction model that uses the format:
Input:  "CORRUPT: wakl SENTENCE: [MASK] to the shops"
Target: ["walk"]
"""

import torch
import argparse
from transformers import DistilBertForMaskedLM, DistilBertTokenizer
from enhanced_two_stage import EnhancedTypoCorrector

class ExplicitTypoCorrector(EnhancedTypoCorrector):
    """Corrector using explicit typo format model."""
    
    def __init__(self, explicit_model_path: str):
        """Initialize with explicit typo model."""
        
        # Initialize spell checker (same as parent)
        try:
            from spellchecker import SpellChecker
            self.spell = SpellChecker()
            print("‚úÖ Enhanced spell checker initialized")
        except ImportError:
            self.spell = None
            print("‚ùå Spell checker not available")
        
        # Load the explicit typo model
        print(f"‚úÖ Loading explicit typo model: {explicit_model_path}")
        self.tokenizer = DistilBertTokenizer.from_pretrained(explicit_model_path)
        self.model = DistilBertForMaskedLM.from_pretrained(explicit_model_path)
        self.model.eval()
        
        # Same enhanced dictionaries as parent
        self.common_typos = {
            'sis': 'is', 'thi': 'this', 'stor': 'store', 'som': 'some',
            'ther': 'there', 'mistaks': 'mistakes', 'sentenc': 'sentence',
            'sentance': 'sentence', 'quikc': 'quick', 'teh': 'the',
            'beutiful': 'beautiful', 'outsid': 'outside', 'wiht': 'with',
            'recieve': 'receive', 'seperate': 'separate', 'definately': 'definitely',
            'problme': 'problem'
        }
        
        self.homophones = {
            'too': ['to', 'two'], 'to': ['too', 'two'], 'two': ['too', 'to'],
            'there': ['their', "they're"], 'their': ['there', "they're"],
            "they're": ['there', 'their'], 'theyre': ['there', 'their'],
            'your': ["you're"], "you're": ['your'], 'youre': ['your'],
            'its': ["it's"], "it's": ['its'], 'affect': ['effect'], 'effect': ['affect'],
        }
        
        self.apostrophe_rules = {
            'its': "it's", 'cant': "can't", 'dont': "don't", 'wont': "won't",
            'isnt': "isn't", 'arent': "aren't", 'wasnt': "wasn't", 'werent': "weren't",
            'hasnt': "hasn't", 'havent': "haven't", 'hadnt': "hadn't",
            'shouldnt': "shouldn't", 'wouldnt': "wouldn't", 'couldnt': "couldn't",
        }
    
    def correct_word_with_explicit_mlm(self, text: str, typo_word: str, top_k: int = 10) -> list:
        """Use explicit typo format for correction."""
        
        # Use explicit format: "CORRUPT: typo SENTENCE: [MASK] context"
        masked_text = text.replace(typo_word, '[MASK]', 1)
        explicit_input = f"CORRUPT: {typo_word} SENTENCE: {masked_text}"
        
        # Get predictions using explicit format (this should be very confident)
        candidates = self._get_explicit_mlm_predictions(explicit_input, typo_word, top_k)
        
        # If explicit MLM gives good results, use them
        if candidates and candidates[0][1] > 0.5:  # High confidence threshold
            return candidates
        
        # Fallback to dictionaries if MLM confidence is low
        if typo_word in self.common_typos:
            return [(self.common_typos[typo_word], 0.95)]
        
        if typo_word in self.apostrophe_rules:
            return [(self.apostrophe_rules[typo_word], 0.90)]
        
        # Final fallback to spell checker
        if self.spell:
            suggestions = list(self.spell.candidates(typo_word))
            for suggestion in suggestions[:3]:
                edit_dist = self._levenshtein_distance(typo_word.lower(), suggestion.lower())
                spell_score = max(0.2, 1.0 - (edit_dist * 0.2))
                candidates.append((suggestion, spell_score))
        
        return candidates[:top_k]
    
    def _get_explicit_mlm_predictions(self, explicit_text: str, original_word: str, top_k: int = 10) -> list:
        """Get predictions using explicit typo format."""
        
        inputs = self.tokenizer(explicit_text, return_tensors='pt')
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            
            # Find mask position
            mask_token_index = torch.where(inputs['input_ids'] == self.tokenizer.mask_token_id)[1]
            
            if len(mask_token_index) == 0:
                return []
            
            mask_logits = logits[0, mask_token_index[0], :]
            
            # Get top-k predictions
            top_k_tokens = torch.topk(mask_logits, top_k, dim=-1)
            
            candidates = []
            for i in range(top_k):
                token_id = top_k_tokens.indices[i].item()
                token = self.tokenizer.decode([token_id]).strip()
                base_score = torch.softmax(mask_logits, dim=-1)[token_id].item()
                
                # Enhanced filtering and scoring
                if (token.isalpha() and len(token) > 1 and 
                    not token.startswith('##') and 
                    token.lower() != original_word.lower()):
                    
                    # Boost score for explicit format
                    explicit_bonus = 0.1  # Explicit format should be more reliable
                    enhanced_score = base_score + explicit_bonus
                    
                    candidates.append((token, enhanced_score))
            
            return candidates
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """Calculate Levenshtein distance."""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]

def test_explicit_format():
    """Test explicit typo correction format directly."""
    
    print("üîç TESTING EXPLICIT FORMAT DIRECTLY")
    print("="*60)
    
    model_path = "models/explicit_typo_mlm"
    
    try:
        tokenizer = DistilBertTokenizer.from_pretrained(model_path)
        model = DistilBertForMaskedLM.from_pretrained(model_path)
        model.eval()
        
        test_cases = [
            ("CORRUPT: wiht SENTENCE: Can you help me [MASK] this problem?", "with"),
            ("CORRUPT: beutiful SENTENCE: It's a [MASK] day outside.", "beautiful"),
            ("CORRUPT: recieve SENTENCE: I will [MASK] the package tomorrow.", "receive"),
            ("CORRUPT: quikc SENTENCE: That was a [MASK] response.", "quick"),
            ("CORRUPT: ther SENTENCE: [MASK] are many options.", "there"),
            ("CORRUPT: wakl SENTENCE: I want to [MASK] to the store.", "walk"),
        ]
        
        print("Direct explicit format predictions:")
        print("-" * 40)
        
        for explicit_input, expected in test_cases:
            inputs = tokenizer(explicit_input, return_tensors='pt')
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits = outputs.logits
                
                # Find mask position
                mask_positions = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]
                
                if len(mask_positions) > 0:
                    mask_logits = logits[0, mask_positions[0], :]
                    top_5 = torch.topk(mask_logits, 5)
                    
                    print(f"\nInput: '{explicit_input}'")
                    print(f"Expected: '{expected}'")
                    print("Predictions:")
                    
                    found_expected = False
                    for i in range(5):
                        token_id = top_5.indices[i].item()
                        token = tokenizer.decode([token_id]).strip()
                        score = torch.softmax(mask_logits, dim=-1)[token_id].item()
                        
                        marker = " ‚úÖ" if token.lower() == expected.lower() else ""
                        if token.lower() == expected.lower():
                            found_expected = True
                            
                        print(f"  {i+1}. '{token}' ({score:.3f}){marker}")
                    
                    if not found_expected:
                        print(f"  ‚ùå Expected '{expected}' not in top 5")
        
    except Exception as e:
        print(f"‚ùå Error testing explicit model: {e}")
        print("üí° Make sure to train the model first with: python3 explicit_typo_training.py")

def test_explicit_corrector_validation():
    """Test explicit corrector on validation set."""
    
    print("\n" + "="*60)
    print("üéØ TESTING EXPLICIT CORRECTOR ON VALIDATION SET")
    print("="*60)
    
    # Same test cases as validation
    test_cases = [
        ("Thi sis a test sentenc with typos", "This is a test sentence with typos"),
        ("The quikc brown fox jumps over teh lazy dog", "The quick brown fox jumps over the lazy dog"),
        ("I went too the stor to buy som milk", "I went to the store to buy some milk"),
        ("Ther are many mistaks in this sentance", "There are many mistakes in this sentence"),
        ("Its a beutiful day outsid today", "It's a beautiful day outside today"),
        ("Can you help me wiht this problme?", "Can you help me with this problem?"),
        ("They're going to there house over their", "They're going to their house over there"),
        ("Your presentation was excellent, you're very talented", "Your presentation was excellent, you're very talented"),
        ("The affect of this change will effect everyone", "The effect of this change will affect everyone"),
        ("I need advise about how to advice my team", "I need advice about how to advise my team")
    ]
    
    try:
        corrector = ExplicitTypoCorrector("models/explicit_typo_mlm")
        
        # Calculate metrics
        stats = {
            'total_cases': len(test_cases),
            'corrections_made': 0,
            'exact_matches': 0,
            'partial_improvements': 0,
            'total_tokens': 0,
            'correct_tokens': 0
        }
        
        print("\nDETAILED RESULTS:")
        print("-" * 60)
        
        for i, (corrupted, expected) in enumerate(test_cases, 1):
            corrected, info = corrector.correct_text(corrupted)
            
            print(f"\n{i:2d}. Corrupted: '{corrupted}'")
            print(f"    Expected:  '{expected}'")
            print(f"    Explicit:  '{corrected}' ({info['total_corrections']} corrections)")
            
            # Check if correction was attempted
            if info['total_corrections'] > 0:
                stats['corrections_made'] += 1
            
            # Check exact match
            if corrected.lower().strip() == expected.lower().strip():
                stats['exact_matches'] += 1
                print(f"    ‚úÖ EXACT MATCH!")
            
            # Calculate token-level accuracy
            orig_tokens = corrupted.lower().split()
            pred_tokens = corrected.lower().split()
            exp_tokens = expected.lower().split()
            
            improvements = 0
            max_len = max(len(pred_tokens), len(exp_tokens), len(orig_tokens))
            
            for j in range(max_len):
                orig_token = orig_tokens[j] if j < len(orig_tokens) else ""
                pred_token = pred_tokens[j] if j < len(pred_tokens) else ""
                exp_token = exp_tokens[j] if j < len(exp_tokens) else ""
                
                stats['total_tokens'] += 1
                if pred_token == exp_token:
                    stats['correct_tokens'] += 1
                
                if pred_token == exp_token and orig_token != exp_token:
                    improvements += 1
            
            if improvements > 0:
                stats['partial_improvements'] += 1
                print(f"    ‚úÖ {improvements} tokens improved")
            
            # Show corrections
            if info['corrections_made']:
                for correction in info['corrections_made']:
                    print(f"    - '{correction['original']}' ‚Üí '{correction['corrected']}' "
                          f"(score: {correction['score']:.3f})")
        
        # Calculate final metrics
        token_accuracy = stats['correct_tokens'] / stats['total_tokens'] * 100
        exact_match_rate = stats['exact_matches'] / stats['total_cases'] * 100
        partial_improvement_rate = stats['partial_improvements'] / stats['total_cases'] * 100
        correction_attempt_rate = stats['corrections_made'] / stats['total_cases'] * 100
        
        print("\n" + "="*60)
        print("üìä EXPLICIT TYPO CORRECTOR RESULTS")
        print("="*60)
        
        print(f"üìä Total test cases: {stats['total_cases']}")
        print(f"üìä Token accuracy: {token_accuracy:.1f}%")
        print(f"üìä Exact matches: {stats['exact_matches']} ({exact_match_rate:.1f}%)")
        print(f"üìä Partial improvements: {stats['partial_improvements']} ({partial_improvement_rate:.1f}%)")
        print(f"üìä Corrections attempted: {stats['corrections_made']} ({correction_attempt_rate:.1f}%)")
        
        print(f"\nüéØ PERFORMANCE vs TARGETS:")
        print(f"   Token Accuracy: {token_accuracy:.1f}% (Target: 90%+) {'‚úÖ' if token_accuracy >= 90 else '‚ùå'}")
        print(f"   Exact Matches: {exact_match_rate:.1f}% (Target: 60%+) {'‚úÖ' if exact_match_rate >= 60 else '‚ùå'}")
        
        # Comparison with final corrector
        print(f"\nüìà IMPROVEMENT vs FINAL CORRECTOR:")
        print(f"   Token Accuracy: {token_accuracy:.1f}% (was 90.8%) = {token_accuracy-90.8:+.1f}%")
        print(f"   Exact Matches: {exact_match_rate:.1f}% (was 60.0%) = {exact_match_rate-60.0:+.1f}%")
        
        if token_accuracy >= 90:
            print(f"\nüéâ SUCCESS: Explicit format achieves 90%+ target! ({token_accuracy:.1f}% >= 90%)")
        else:
            remaining_gap = 90 - token_accuracy
            print(f"\nüîß REMAINING GAP: {remaining_gap:.1f}% to reach 90% target")
        
        return token_accuracy
        
    except Exception as e:
        print(f"‚ùå Error testing explicit corrector: {e}")
        print("üí° Make sure to train the model first with: python3 explicit_typo_training.py")
        return 0

def main():
    parser = argparse.ArgumentParser(description="Test explicit typo correction model")
    parser.add_argument('--model_path', type=str, default='models/explicit_typo_mlm')
    
    args = parser.parse_args()
    
    print("üß™ TESTING EXPLICIT TYPO CORRECTION MODEL")
    print("="*70)
    print(f"üìÅ Model path: {args.model_path}")
    print(f"üìù Format: 'CORRUPT: typo SENTENCE: [MASK] context' ‚Üí 'correct'")
    
    # Test explicit format directly
    test_explicit_format()
    
    # Test on validation set
    accuracy = test_explicit_corrector_validation()
    
    if accuracy >= 90:
        print(f"\nüèÜ MISSION ACCOMPLISHED!")
        print(f"   Final accuracy: {accuracy:.1f}%")
        print(f"   Explicit format: ‚úÖ Works brilliantly")
        print(f"   Training approach: ‚úÖ CORRUPT: typo SENTENCE: [MASK] context")

if __name__ == "__main__":
    main()